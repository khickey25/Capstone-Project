{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Baseline\n",
    "\n",
    "This notebook will build a basic logistic regression model and evaluate results using cross-validation.\n",
    "\n",
    "1. Read in the data\n",
    "2. Create hold-out test set\n",
    "3. Create pipeline for logistic regression. \n",
    "    - Random Oversample of data to balance out target.\n",
    "    - cross-validation of results; evaluation metrics are accuracy, f1 score, and AUC. \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khickey/anaconda3/lib/python3.6/site-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from data_import import preprocess_data\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, cross_validate\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from Evaluation import eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khickey/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#load in the preprocessed data\n",
    "data = preprocess_data('Statcast_data.csv')\n",
    "target = data['description']\n",
    "#filter out 'player_name'; will not use as a feature\n",
    "data = data.iloc[:, :-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first, create a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state = 777, test_size = .2)\n",
    "\n",
    "#then instatiate the model we will use: Logistic Regression\n",
    "log_reg = LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model and Interpret\n",
    "\n",
    "Build a model and apply interpretation of model on the results. This involves analyzing the values of the coefficients.\n",
    "\n",
    "Train on one fold of training data, and test on a validation set. We will randomely oversample to balance out the ratio of classes in the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test Accuracy score: 0.49475850287311696\n",
      " Test AUC score: 0.5438088316722038\n",
      " Test F1 score: 0.46335931378613554\n"
     ]
    }
   ],
   "source": [
    "ros = RandomOverSampler(ratio = 1, random_state =777)\n",
    "\n",
    "X_os, y_os = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "log_reg.fit(X_os, y_os)\n",
    "\n",
    "y_pred_logreg = log_reg.predict(X_test)\n",
    "\n",
    "print(f\" Test Accuracy score: {accuracy_score(y_test, y_pred_logreg)}\")\n",
    "print(f\" Test AUC score: {roc_auc_score(y_test, y_pred_logreg)}\")\n",
    "print(f\" Test F1 score: {f1_score(y_test, y_pred_logreg)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "release_speed coefficient: 0.06911968625592822\n",
      "release_spin_rate coefficient: 0.00276223713076353\n",
      "release_pos_x coefficient: 0.017508759277576218\n",
      "release_pos_y coefficient: 0.48146282067779284\n",
      "release_pos_z coefficient: -0.0011657378185506147\n",
      "pfx_x coefficient: 0.08050853168377756\n",
      "pfx_z coefficient: 0.13044940176037795\n",
      "vx0 coefficient: -0.011622473367725728\n",
      "vy0 coefficient: 0.12407318150772563\n",
      "vz0 coefficient: 0.00202079165490292\n",
      "ax coefficient: -0.10879181621088845\n",
      "ay coefficient: -0.013328955716309578\n",
      "az coefficient: -0.08995007570798766\n",
      "sz_top coefficient: 0.0018661102717056513\n",
      "sz_bot coefficient: -0.0003097677234898032\n",
      "release_extension coefficient: 0.47920587517046037\n",
      "pitch_name_2-Seam Fastball coefficient: 0.2516369510978865\n",
      "pitch_name_4-Seam Fastball coefficient: 0.2763296571980953\n",
      "pitch_name_Changeup coefficient: -0.49606918039456654\n",
      "pitch_name_Curveball coefficient: 0.14274307306521972\n",
      "pitch_name_Cutter coefficient: 0.05538028109718202\n",
      "pitch_name_Sinker coefficient: 0.349736800251894\n",
      "pitch_name_Slider coefficient: -0.010239848943596086\n",
      "pitch_name_Split Finger coefficient: -0.7801074837686148\n",
      "pitch_name_nan coefficient: 0.07773725477442159\n"
     ]
    }
   ],
   "source": [
    "for idx, feature in enumerate(X_train.columns):\n",
    "    print(f\"{feature} coefficient: {log_reg.coef_[0][idx]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Looking at the coefficients, there is one main property that can be interpreted: the signage, which can ultimately help determine the odds ratio for each feature. Negative value coefficients result in a odds ratio below 1, meaning that one unit change in that feature will lower the chance of a positive target value, in this case a strike. A positive value will indicate produce a positive odds ratio, meaning that a one unit change in that feature will make it more likely of a resulting strike. This however, assumes holding all other features constant, which is highly impractical.\n",
    "\n",
    "cite: http://www.appstate.edu/~whiteheadjc/service/logit/intro.htm#interp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "\n",
    "#### Use Cross-validation to ensure reliability of results above.\n",
    "\n",
    "Use custom function in `Evaluation.py` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean test_accuracy Value: 0.48894387316710847\n",
      "test_accuracy scores: [0.48599854 0.49157971 0.49174917 0.48454109 0.49085085]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'train_accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-767b3112cd60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Capstone-Project/Baseball_Data/Evaluation.py\u001b[0m in \u001b[0;36meval_model\u001b[0;34m(clf, X, y, cv)\u001b[0m\n\u001b[1;32m     28\u001b[0m     for result in ['test_accuracy','train_accuracy','test_f1',\n\u001b[1;32m     29\u001b[0m                'train_f1','test_roc_auc','train_roc_auc']:\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Mean {result} Value: {np.mean(cv_results[result])}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{result} scores: {cv_results[result]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'train_accuracy'"
     ]
    }
   ],
   "source": [
    "eval_model(log_reg, X_train, y_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
